{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba47d97-7414-49a5-a2b3-129cbef4bdb0",
   "metadata": {},
   "source": [
    "# AOB MC Data Exploration\n",
    "The goal of this notebook is to take in data from Zhuang et al. (see other notebooks) and be able to explore spatial transcriptomics of AOB MCs, specifically. This will be done in a few steps including:\n",
    "* data loading\n",
    "* joining dataframes\n",
    "* filtering for excitatory neurons within the accessory olfactory bulb\n",
    "* visualizing genetic diversity of these neurons\n",
    "\n",
    "This notebook has been created to enable greater visualization of the analysis performed in AOB_MC_data_exploration.py within this repository. Please note that much of this code has been adapted from code provided by the Allen Brain Institute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae03885-b3e4-438d-805c-55b3f625b522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git (from abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Cloning https://github.com/alleninstitute/abc_atlas_access.git to c:\\users\\kevjm\\appdata\\local\\temp\\pip-install-bgyyz6pe\\abc-atlas-access_2ac1866e72c04a7381156c9c1d63f569\n",
      "  Resolved https://github.com/alleninstitute/abc_atlas_access.git to commit 398c9cc557a4b1e75dc68dd3d4965d3ed50367b2\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting anndata (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading anndata-0.12.1-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting boto3 (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading boto3-1.39.13-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2.2.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (4.67.1)\n",
      "Collecting geojson (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading geojson-3.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (3.10.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (1.15.3)\n",
      "Collecting simpleitk (from abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading simpleitk-2.5.2-cp311-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "Collecting array-api-compat>=1.7.1 (from anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: h5py>=3.8 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (3.12.1)\n",
      "Collecting legacy-api-wrap (from anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting natsort (from anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=24.2 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (24.2)\n",
      "Collecting zarr!=3.0.*,>=2.18.7 (from anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading zarr-3.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from pandas->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from pandas->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from pandas->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (1.17.0)\n",
      "Collecting donfig>=0.8 (from zarr!=3.0.*,>=2.18.7->anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading numcodecs-0.16.1-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from zarr!=3.0.*,>=2.18.7->anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (4.12.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from donfig>=0.8->zarr!=3.0.*,>=2.18.7->anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (6.0.2)\n",
      "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading crc32c-2.7.1-cp313-cp313-win_amd64.whl.metadata (7.5 kB)\n",
      "Collecting botocore<1.40.0,>=1.39.13 (from boto3->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading botocore-1.39.13-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from boto3->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (1.0.1)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git)\n",
      "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from botocore<1.40.0,>=1.39.13->boto3->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from matplotlib->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from matplotlib->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from matplotlib->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from matplotlib->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from matplotlib->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from matplotlib->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from pydantic->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from pydantic->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevjm\\anaconda3\\lib\\site-packages (from tqdm->abc_atlas_access@ git+https://github.com/alleninstitute/abc_atlas_access.git->abc_atlas_access[notebooks]@ git+https://github.com/alleninstitute/abc_atlas_access.git) (0.4.6)\n",
      "Downloading anndata-0.12.1-py3-none-any.whl (169 kB)\n",
      "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
      "Downloading zarr-3.1.0-py3-none-any.whl (254 kB)\n",
      "Downloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
      "Downloading numcodecs-0.16.1-cp313-cp313-win_amd64.whl (785 kB)\n",
      "   ---------------------------------------- 0.0/785.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 785.6/785.6 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading crc32c-2.7.1-cp313-cp313-win_amd64.whl (39 kB)\n",
      "Downloading boto3-1.39.13-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.39.13-py3-none-any.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 4.2/13.9 MB 19.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.1/13.9 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.9/13.9 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.9/13.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.2/13.9 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.5/13.9 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.6/13.9 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.6/13.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "Downloading geojson-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading simpleitk-2.5.2-cp311-abi3-win_amd64.whl (18.8 MB)\n",
      "   ---------------------------------------- 0.0/18.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.8/18.8 MB 11.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 3.1/18.8 MB 7.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 4.2/18.8 MB 6.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 5.2/18.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 6.3/18.8 MB 6.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 7.3/18.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 8.4/18.8 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 9.4/18.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 10.5/18.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 11.5/18.8 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 12.6/18.8 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 12.8/18.8 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 13.1/18.8 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 13.4/18.8 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 13.6/18.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 13.9/18.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 14.2/18.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 14.4/18.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 14.7/18.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 14.9/18.8 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 15.2/18.8 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 15.5/18.8 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.7/18.8 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 16.0/18.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 16.3/18.8 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.5/18.8 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.8/18.8 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.0/18.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.3/18.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.6/18.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.8/18.8 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.1/18.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.4/18.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.6/18.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.8/18.8 MB 2.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: abc_atlas_access\n",
      "  Building wheel for abc_atlas_access (pyproject.toml): started\n",
      "  Building wheel for abc_atlas_access (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for abc_atlas_access: filename=abc_atlas_access-0.7.0-py3-none-any.whl size=21820 sha256=c846ad26832e1c3b3d1296750364b6f1ccf3899dfcafce60e742d434a25ae5de\n",
      "  Stored in directory: C:\\Users\\kevjm\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-1em0wk2m\\wheels\\04\\ae\\cf\\b1a2f84719279a1d942547932810ad9e3b0e080862a1e3c2e8\n",
      "Successfully built abc_atlas_access\n",
      "Installing collected packages: simpleitk, numcodecs, natsort, legacy-api-wrap, geojson, donfig, crc32c, array-api-compat, botocore, zarr, s3transfer, boto3, anndata, abc_atlas_access\n",
      "\n",
      "   ----------------------------------------  0/14 [simpleitk]\n",
      "   ----------------------------------------  0/14 [simpleitk]\n",
      "   ----------------------------------------  0/14 [simpleitk]\n",
      "   ----------------------------------------  0/14 [simpleitk]\n",
      "   ----------------------------------------  0/14 [simpleitk]\n",
      "   -- -------------------------------------  1/14 [numcodecs]\n",
      "   -- -------------------------------------  1/14 [numcodecs]\n",
      "   -- -------------------------------------  1/14 [numcodecs]\n",
      "   ----- ----------------------------------  2/14 [natsort]\n",
      "   ----------- ----------------------------  4/14 [geojson]\n",
      "   -------------- -------------------------  5/14 [donfig]\n",
      "   -------------------- -------------------  7/14 [array-api-compat]\n",
      "   -------------------- -------------------  7/14 [array-api-compat]\n",
      "  Attempting uninstall: botocore\n",
      "   -------------------- -------------------  7/14 [array-api-compat]\n",
      "    Found existing installation: botocore 1.36.3\n",
      "   -------------------- -------------------  7/14 [array-api-compat]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "    Uninstalling botocore-1.36.3:\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "      Successfully uninstalled botocore-1.36.3\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ---------------------- -----------------  8/14 [botocore]\n",
      "   ------------------------- --------------  9/14 [zarr]\n",
      "   ------------------------- --------------  9/14 [zarr]\n",
      "   ------------------------- --------------  9/14 [zarr]\n",
      "   ------------------------- --------------  9/14 [zarr]\n",
      "   ------------------------- --------------  9/14 [zarr]\n",
      "   ---------------------------- ----------- 10/14 [s3transfer]\n",
      "   ---------------------------- ----------- 10/14 [s3transfer]\n",
      "   ------------------------------- -------- 11/14 [boto3]\n",
      "   ------------------------------- -------- 11/14 [boto3]\n",
      "   ---------------------------------- ----- 12/14 [anndata]\n",
      "   ---------------------------------- ----- 12/14 [anndata]\n",
      "   ---------------------------------- ----- 12/14 [anndata]\n",
      "   ---------------------------------- ----- 12/14 [anndata]\n",
      "   ---------------------------------- ----- 12/14 [anndata]\n",
      "   ---------------------------------------- 14/14 [abc_atlas_access]\n",
      "\n",
      "Successfully installed abc_atlas_access-0.7.0 anndata-0.12.1 array-api-compat-1.12.0 boto3-1.39.13 botocore-1.39.13 crc32c-2.7.1 donfig-0.8.1.post1 geojson-3.2.0 legacy-api-wrap-1.4.1 natsort-8.4.0 numcodecs-0.16.1 s3transfer-0.13.1 simpleitk-2.5.2 zarr-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/alleninstitute/abc_atlas_access.git 'C:\\Users\\kevjm\\AppData\\Local\\Temp\\pip-install-bgyyz6pe\\abc-atlas-access_2ac1866e72c04a7381156c9c1d63f569'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.39.13 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# if using for the first time, you will need to download the Allen Brain-specific functions:\n",
    "!pip install \"abc_atlas_access[notebooks] @ git+https://github.com/alleninstitute/abc_atlas_access.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1907ef-6a63-4103-99c2-653e6546c892",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# defining functions for visualization\n",
    "# This code has been provided by the Allen Brain Institute\n",
    "def subplot_section(ax, xx, yy, cc = None, val = None, cmap = None) :\n",
    "    \n",
    "    if cmap is not None :\n",
    "        ax.scatter(xx, yy, s=0.5, c=val, marker='.', cmap=cmap)\n",
    "    elif cc is not None :\n",
    "        ax.scatter(xx, yy, s=0.5, color=cc, marker='.')\n",
    "    ax.set_ylim(11, 0)\n",
    "    ax.set_xlim(0, 11)\n",
    "    ax.axis('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "def plot_sections(cell_extended, example_section, cc = None, val = None, fig_width = 10, fig_height = 10, cmap = None) :\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2)\n",
    "    fig.set_size_inches(fig_width, fig_height)\n",
    "    \n",
    "    for i, d in enumerate(cell_extended):\n",
    "        \n",
    "        pred = (cell_extended[d]['brain_section_label'] == example_section[d])\n",
    "        section = cell_extended[d][pred] \n",
    "        \n",
    "        if cmap is not None :\n",
    "            subplot_section( ax.flat[i], section['x'], section['y'], val=section[val], cmap=cmap)\n",
    "        elif cc is not None :\n",
    "            subplot_section( ax.flat[i], section['x'], section['y'], section[cc])\n",
    "            \n",
    "        ax.flat[i].set_title(d)\n",
    "        \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_heatmap(df, fig_width = 8, fig_height = 4, cmap=plt.cm.magma_r, vmax=None):\n",
    "\n",
    "    arr = df.to_numpy()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(fig_width, fig_height)\n",
    "\n",
    "    res = ax.imshow(arr, cmap=cmap, aspect='auto', vmax=vmax)\n",
    "    xlabs = df.columns.values\n",
    "    ylabs = df.index.values\n",
    "\n",
    "    ax.set_xticks(range(len(xlabs)))\n",
    "    ax.set_xticklabels(xlabs)\n",
    "\n",
    "    ax.set_yticks(range(len(ylabs)))\n",
    "    res = ax.set_yticklabels(ylabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe192344-bd36-4603-a4d4-6610debb5654",
   "metadata": {},
   "source": [
    "## Imports and loading of relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cdbc99a-57d5-4507-96ff-6b656a32f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries and Allen-specific packages to engage with datasets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import anndata\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abc_atlas_access.abc_atlas_cache.abc_project_cache import AbcProjectCache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aead1e2b-d78b-4a6d-8fcd-a54eeb07f48f",
   "metadata": {},
   "source": [
    "## Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29dfd1-cdd8-4a86-9a20-ea90650b1109",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd29d4f4-0bb7-42bd-bbd8-bea5981ed6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for all Zhuang datasets\n",
    "datasets = ['Zhuang-ABCA-1', 'Zhuang-ABCA-2', 'Zhuang-ABCA-3'] #excluding ...-4 as it does not have any AOB neurons\n",
    "# loading / caching relevant data:\n",
    "# download_base = Path('C:/Users/IGD/Documents/KJM/data/abc_10x/data/abc_atlas') # work computer\n",
    "download_base = Path('C:/Users/kevjm/Documents/Python/downloaded_data/ABC_10X') # personal laptop\n",
    "abc_cache = AbcProjectCache.from_cache_dir(download_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c67161-0c94-4a16-8861-501abefb4d78",
   "metadata": {},
   "source": [
    "### Create variable cell_extended to contain data from provided datasets\n",
    "These next few cells will download and combine relevant data for future analysis. Some notes:\n",
    "* Cluster refers to the clusters ABI defined based on genes expressed\n",
    "* CCF refers to the coordinates of a given cell within the ABI centralized framework\n",
    "* Parcellation refers to the brain area where a cell was found\n",
    "\n",
    "The steps within the following cells are performed by the create_cell_extended function defined in combining_filtering_abc_data.py within this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ce38be-ca69-4f4d-8a14-05493b35d210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cluster_to_cluster_annotation_membership_pivoted.csv: 100%|██████████| 531k/531k [00:00<00:00, 890kMB/s]  \n",
      "cluster_to_cluster_annotation_membership_color.csv: 100%|██████████| 239k/239k [00:00<00:00, 812kMB/s]  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Reading in cluster details and providing color for consistent labeling\n",
    "cluster_details = abc_cache.get_metadata_dataframe(\n",
    "    directory='WMB-taxonomy',\n",
    "    file_name='cluster_to_cluster_annotation_membership_pivoted',\n",
    "    keep_default_na=False\n",
    ")\n",
    "\n",
    "cluster_details.set_index('cluster_alias', inplace=True)\n",
    "cluster_colors = abc_cache.get_metadata_dataframe(\n",
    "    directory='WMB-taxonomy',\n",
    "    file_name='cluster_to_cluster_annotation_membership_color',\n",
    ")\n",
    "cluster_colors.set_index('cluster_alias', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef999c4-a954-45af-83f6-f210a0617a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cell_metadata.csv: 100%|██████████| 661M/661M [08:21<00:00, 1.32MMB/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhuang-ABCA-1 : Number of cells =  2846908 ,  Number of sections = 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccf_coordinates.csv: 100%|██████████| 221M/221M [02:39<00:00, 1.39MMB/s]    \n",
      "cell_metadata.csv: 100%|██████████| 286M/286M [03:41<00:00, 1.29MMB/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhuang-ABCA-2 : Number of cells =  1227408 ,  Number of sections = 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccf_coordinates.csv: 100%|██████████| 89.1M/89.1M [01:05<00:00, 1.36MMB/s]   \n",
      "cell_metadata.csv: 100%|██████████| 369M/369M [04:49<00:00, 1.28MMB/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhuang-ABCA-3 : Number of cells =  1585843 ,  Number of sections = 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccf_coordinates.csv: 100%|██████████| 132M/132M [01:37<00:00, 1.35MMB/s]   \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load in cell metadata and coordinate information\n",
    "# for each dataframe (as defined by list above)\n",
    "print('Creating components...')\n",
    "cell = {}\n",
    "ccf_coordinates = {}\n",
    "for d in datasets :\n",
    "    #for each dataset, \n",
    "    # load in the metadata\n",
    "    cell[d] = abc_cache.get_metadata_dataframe(\n",
    "        directory=d,\n",
    "        file_name='cell_metadata',\n",
    "        dtype={\"cell_label\": str}\n",
    "    )\n",
    "    cell[d].set_index('cell_label', inplace=True)\n",
    "    sdf = cell[d].groupby('brain_section_label')          \n",
    "    print(d,\":\",\"Number of cells = \", len(cell[d]), \", \", \"Number of sections =\", len(sdf))\n",
    "\n",
    "    # and load in the coordinate information\n",
    "    ccf_coordinates[d] = abc_cache.get_metadata_dataframe(directory=f\"{d}-CCF\", file_name='ccf_coordinates')\n",
    "    ccf_coordinates[d].set_index('cell_label', inplace=True)\n",
    "    ccf_coordinates[d].rename(columns={'x': 'x_ccf',\n",
    "                                       'y': 'y_ccf',\n",
    "                                       'z': 'z_ccf'},\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d8f2403-6bd8-45e2-81a8-d2883cc58e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parcellation_to_parcellation_term_membership_acronym.csv: 100%|██████████| 22.3k/22.3k [00:00<00:00, 68.7kMB/s]\n",
      "parcellation_to_parcellation_term_membership_color.csv: 100%|██████████| 30.5k/30.5k [00:00<00:00, 110kMB/s] \n"
     ]
    }
   ],
   "source": [
    "#Step 3: Load in Parcellation Data (defines what brain region a cell is in)\n",
    "parcellation_annotation = abc_cache.get_metadata_dataframe(directory=\"Allen-CCF-2020\",\n",
    "                                                           file_name='parcellation_to_parcellation_term_membership_acronym')   \n",
    "parcellation_annotation.set_index('parcellation_index', inplace=True)\n",
    "parcellation_annotation.columns = ['parcellation_%s'% x for x in  parcellation_annotation.columns]\n",
    "parcellation_color = abc_cache.get_metadata_dataframe(directory=\"Allen-CCF-2020\",      \n",
    "                                                      file_name='parcellation_to_parcellation_term_membership_color')\n",
    "parcellation_color.set_index('parcellation_index', inplace=True)\n",
    "parcellation_color.columns = ['parcellation_%s'% x for x in  parcellation_color.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42bc4044-67c1-4df3-b73e-1a19c3edf5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Combine all relevant data into cell_extended variable\n",
    "cell_extended = {}\n",
    "for d in datasets :\n",
    "    cell_extended[d] = cell[d].join(cluster_details, on='cluster_alias')\n",
    "    cell_extended[d] = cell_extended[d].join(cluster_colors, on='cluster_alias')\n",
    "    cell_extended[d] = cell_extended[d].join(ccf_coordinates[d], how='inner')\n",
    "    cell_extended[d] = cell_extended[d].join(parcellation_annotation, on='parcellation_index')\n",
    "    cell_extended[d] = cell_extended[d].join(parcellation_color, on='parcellation_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be924a7-0c99-4871-ab7c-51eb31fd0a25",
   "metadata": {},
   "source": [
    "### Filtering expression data to AOB Glutamatergic Neurons\n",
    "These cells will select from the whole-brain datasets only those cells that are (1) within the accessory olfactory bulb (AOB) and (2) use glutamate as their neurotransmitter. Within the AOB, glutamatergic neurons are either mitral or tufted cells; here we are combining them as one population.\n",
    "\n",
    "The steps within the following cells are performed by the filter_cell_extended function defined in combining_filtering_abc_data.py within this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aaf05c8-780a-4c9c-949b-6f4c0e45752f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhuang-ABCA-1: 1050 Glut-ergic neurons within AOB\n",
      "Zhuang-ABCA-2: 370 Glut-ergic neurons within AOB\n",
      "Zhuang-ABCA-3: 458 Glut-ergic neurons within AOB\n"
     ]
    }
   ],
   "source": [
    "# Define filtering parameters\n",
    "structure_mask = 'AOB'\n",
    "nt_mask = 'Glut'\n",
    "\n",
    "# creating a new dataframe only with glutamatergic cells within the olfactory bulb\n",
    "cell_extended_filt = {}\n",
    "for key in cell_extended:\n",
    "    curr_df = cell_extended[key]\n",
    "    cell_extended_filt[key] = curr_df.loc[\n",
    "        (curr_df['parcellation_structure'] == structure_mask) &\n",
    "        (curr_df['neurotransmitter'] == nt_mask)]\n",
    "    print(f'{key}: {cell_extended_filt[key].shape[0]} {nt_mask}-ergic neurons within {structure_mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c606e8b-edc5-4fa5-b31b-d72d04680c23",
   "metadata": {},
   "source": [
    "### Add gene expression data to the filtered dataframe\n",
    "The following cells will retrieve gene expression data for each cell from one dataframe and merge it with the filtered dataframe created above. This will be done through defining a function that takes a dataframe and list of gene names.\n",
    "\n",
    "With a defined function, we can then add an arbitrary amount of genetic data based on certain genes of interest. The code within the following cells is recapitulated in AOB_MC_data_exploration.py and the function add_gene_expression within the combining_filtering_abc_data.py files within this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6da0187e-3aa0-4f68-82a7-73253add3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define a function that adds genetic expression data to a dataframe\n",
    "def add_gene_expression(cell_extended,genes):\n",
    "    \"\"\"\n",
    "    This function incorporates genetic expression data into \n",
    "    a cell_extended dictionary of dataframes. cell_extended is a dictionary of \n",
    "    dataframes and genes is a dataframe with information for screened genes.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Finding expression data for {len(genes)} genes')\n",
    "    # download_base = Path('C:/Users/IGD/Documents/KJM/data/abc_10x/data/abc_atlas') # work computer\n",
    "    download_base = Path('C:/Users/kevjm/Documents/Python/downloaded_data/ABC_10X') # personal laptop\n",
    "    abc_cache = AbcProjectCache.from_cache_dir(download_base)\n",
    "    \n",
    "    cell_w_genex = {}\n",
    "    for key in cell_extended:    \n",
    "        file = abc_cache.get_data_path(directory=key, \n",
    "                                       file_name=f\"{key}/log2\")\n",
    "        \n",
    "        adata = anndata.read_h5ad(file, backed='r')\n",
    "        \n",
    "        start = time.process_time()\n",
    "        gdata = adata[:, genes.index].to_df()\n",
    "        gdata.columns = genes.gene_symbol\n",
    "        cell_w_genex[key] = cell_extended[key].join(gdata)\n",
    "        \n",
    "        print(key,\"-\",\"time taken: \", time.process_time() - start)\n",
    "        \n",
    "        adata.file.close()\n",
    "        del adata\n",
    "    \n",
    "    return cell_w_genex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc98519-0540-4e8a-b039-08d5e35426be",
   "metadata": {},
   "source": [
    "With the function defined, we can name the genes of interest. Note that ABC screened for 1k+ genes which could take a bit of time. Below, I have included code that looks at expression data for a select set of genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088c1a5d-f186-44d9-86f7-5b936723beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gene.csv: 100%|██████████| 84.7k/84.7k [00:00<00:00, 211kMB/s] \n"
     ]
    }
   ],
   "source": [
    "# First, load in all gene expression data\n",
    "# loading in gene data\n",
    "genes = abc_cache.get_metadata_dataframe(directory=datasets[0],\n",
    "                                        file_name='gene')\n",
    "genes.set_index('gene_identifier', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "285a2174-6049-4913-be97-50c11f3f1746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding expression data for 9 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zhuang-ABCA-1-log2.h5ad: 100%|██████████| 2.13G/2.13G [27:57<00:00, 1.27MMB/s]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m gene_bool \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;129;01min\u001b[39;00m gnames \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m genes\u001b[38;5;241m.\u001b[39mgene_symbol]\n\u001b[0;32m      5\u001b[0m genes_filtered \u001b[38;5;241m=\u001b[39m genes[gene_bool]\n\u001b[1;32m----> 7\u001b[0m cell_extended_filt_genex \u001b[38;5;241m=\u001b[39m add_gene_expression(cell_extended_filt,genes_filtered)\n",
      "Cell \u001b[1;32mIn[17], line 22\u001b[0m, in \u001b[0;36madd_gene_expression\u001b[1;34m(cell_extended, genes)\u001b[0m\n\u001b[0;32m     19\u001b[0m adata \u001b[38;5;241m=\u001b[39m anndata\u001b[38;5;241m.\u001b[39mread_h5ad(file, backed\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m---> 22\u001b[0m gdata \u001b[38;5;241m=\u001b[39m adata[:, genes\u001b[38;5;241m.\u001b[39mindex]\u001b[38;5;241m.\u001b[39mto_df()\n\u001b[0;32m     23\u001b[0m gdata\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m genes\u001b[38;5;241m.\u001b[39mgene_symbol\n\u001b[0;32m     24\u001b[0m cell_w_genex[key] \u001b[38;5;241m=\u001b[39m cell_extended[key]\u001b[38;5;241m.\u001b[39mjoin(gdata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\anndata\\_core\\anndata.py:1257\u001b[0m, in \u001b[0;36mAnnData.to_df\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1257\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m   1259\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\anndata\\_core\\anndata.py:558\u001b[0m, in \u001b[0;36mAnnData.X\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;66;03m# This is so that we can index into a backed dense dataset with\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;66;03m# indices that aren’t strictly increasing\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_view:\n\u001b[1;32m--> 558\u001b[0m         X \u001b[38;5;241m=\u001b[39m _subset(X, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oidx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vidx))\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_view \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adata_ref\u001b[38;5;241m.\u001b[39mX \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    560\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\functools.py:934\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    933\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\anndata\\_core\\index.py:228\u001b[0m, in \u001b[0;36m_subset_dataset\u001b[1;34m(d, subset_idx)\u001b[0m\n\u001b[0;32m    226\u001b[0m         rev_order[axis] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(order)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# from hdf5, then to real order\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d[\u001b[38;5;28mtuple\u001b[39m(ordered)][\u001b[38;5;28mtuple\u001b[39m(rev_order)]\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\dataset.py:781\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_reader\u001b[38;5;241m.\u001b[39mread(args)\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# you can filter the genes based on a set list, but it must be a dataframe\n",
    "#for example, here we are selecting a subset of screened genes\n",
    "gnames = ['Slc17a6','Slc32a1','Gnrh1','Esr1','Esr2','Npy1','Npy2','Cyp19a1','Tac2','Crhr1','Crhr2']\n",
    "gene_bool = [x in gnames for x in genes.gene_symbol]\n",
    "genes_filtered = genes[gene_bool]\n",
    "\n",
    "cell_extended_filt_genex = add_gene_expression(cell_extended_filt,genes_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49502fb-728d-445a-9269-509eb5faa8ed",
   "metadata": {},
   "source": [
    "If you wanted to look at the expression data for all genes, then you would skip the filtering step above and pass the genes dataframe as the second argument within the add_gene_expression function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd245ec-9b55-4ece-8627-0fd0ea04c0d3",
   "metadata": {},
   "source": [
    "### Combine separate dataframes into single\n",
    "Right now, the three datasets (Zhuang...-1, Zhuang...-2, and Zhuang...-3) are stored within a dictionary of dataframes. For cross-experiment analysis, we need to combine them into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807e3f3-c25c-4a42-9a5c-0327d44a860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with all data compiled, we can combine across dataframes as follows\n",
    "df_all_datasets = pd.DataFrame()\n",
    "for k in cell_extended_filt_genex:\n",
    "    df_all_datasets = pd.concat([df_all_datasets,\n",
    "                                 cell_extended_filt_genex[k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4dc59c-24e1-481e-a5da-48362a80de32",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd7bbb-60bf-482c-b5ab-4aacb397c4f4",
   "metadata": {},
   "source": [
    "We can now begin visualizing the data! First step is to look at gene expression across neurons for the genes listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e02de-b513-4d14-a57d-4d3e5a9145a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line is included in case there are genes within the list that aren't actually in the allen dataset\n",
    "gnames_in_df = [g_name for g_name in gnames if g_name in df_all_datasets.columns] \n",
    "plot_heatmap(df_all_datasets[gnames_in_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499e4ee-1e5b-4566-9524-76a2155bda20",
   "metadata": {},
   "source": [
    "This is an ongoing project for me and this notebook (along with the other files within this repository) will be updated accordingly. A few questions that I'd like to tackle first are:\n",
    "1) What subpopulations of AOB glutamatergic cells are there? We know that ABI has clustered neurons throughout the brain, but can we define our own clusters of AOB neurons? To this end, I anticipate using dimensionality reduction (e.g., PCA) and clustering algorithms (e.g., hierarchical/agglomerative clustering, k-means clustering, etc.).\n",
    "2) Additionally, these datasets contain genetic expression from male and female mice; I would like to know whether there are any sexually dimorphisms in gene expression. To this end, we can create a sexual dimorphism metric by subtracting the average expression of genes in male datasets from female datasets. From this, we can find whether any genes are more strongly expressed in males or females.\n",
    "3)  Finally, each cell has an anatomical location within the AOB. Sensory input into the AOB is known to be anatomically separate (i.e., sensory neurons expressing the V1-type receptor innervate the anterior AOB whereas sensory neurons expressing hte V2-type receptor innervate the posterior AOB). Are there any genes that have distinct anatomical patterns of expression? To address this, we can define a histogram across the AP axis within the AOB for each gene. Then, we can create a metric with distribution statistics (e.g., median, standard deviation, skew, etc.) to define whether a gene shows specific anatomical patterning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
